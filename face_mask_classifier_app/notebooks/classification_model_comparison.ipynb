{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('localPythonEnv': venv)"
  },
  "interpreter": {
   "hash": "1d4c39e84a00ae3132ad252464a9436a57793414910ce0cf60240e4a7f673481"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset: train=1296, test=139\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data = load('/d/project2/src/svm_processed_data.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "testX = in_encoder.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy = np.argmax(trainy, axis=1)\n",
    "testy = np.argmax(testy, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logistic Regression: Mean Accuracy = 71.23% - SD Accuracy = 7.36%\n",
      "K Nearest Neighbor: Mean Accuracy = 79.23% - SD Accuracy = 10.40%\n",
      "Kernel SVM: Mean Accuracy = 92.44% - SD Accuracy = 4.99%\n",
      "Naive Bayes: Mean Accuracy = 77.01% - SD Accuracy = 8.72%\n",
      "Decision Tree: Mean Accuracy = 72.23% - SD Accuracy = 7.25%\n",
      "Random Forest: Mean Accuracy = 83.89% - SD Accuracy = 10.00%\n"
     ]
    }
   ],
   "source": [
    "classification_models = []\n",
    "classification_models.append(('Logistic Regression', LogisticRegression(solver=\"liblinear\")))\n",
    "classification_models.append(('K Nearest Neighbor', KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\",p=2)))\n",
    "classification_models.append(('Kernel SVM', SVC(kernel = 'rbf',gamma='scale')))\n",
    "classification_models.append(('Naive Bayes', GaussianNB()))\n",
    "classification_models.append(('Decision Tree', DecisionTreeClassifier(criterion = \"entropy\")))\n",
    "classification_models.append(('Random Forest', RandomForestClassifier(n_estimators=100, criterion=\"entropy\")))\n",
    "\n",
    "for name, model in classification_models:\n",
    "  kfold = KFold(n_splits=10)\n",
    "  result = cross_val_score(model, trainX, trainy, cv=kfold, scoring='accuracy')\n",
    "  print(\"%s: Mean Accuracy = %.2f%% - SD Accuracy = %.2f%%\" % (name, result.mean()*100, result.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}